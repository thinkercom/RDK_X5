{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c214df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "# from scipy.special import expit as sigmoid\n",
    "from hobot_dnn import pyeasy_dnn as dnn  # BSP Python API\n",
    "import time\n",
    "import argparse\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f942474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_info(content, log_file=\"log.txt\"):\n",
    "    \"\"\"\n",
    "    记录并打印日志信息\n",
    "    :param content: 日志内容\n",
    "    :param log_file: 日志文件路径，默认为当前目录下的 log.txt\n",
    "    \"\"\"\n",
    "    # 获取当前时间\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    \n",
    "    # 格式化日志信息\n",
    "    log_message = f\"[{current_time}] {content}\"\n",
    "    \n",
    "    # 打印日志到控制台\n",
    "    print(log_message)\n",
    "    \n",
    "    # 将日志写入文件\n",
    "    # with open(log_file, \"a\", encoding=\"utf-8\") as file:\n",
    "    #     file.write(log_message + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b751fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    \"\"\"\n",
    "    预处理图像：letterbox 缩放 + padding\n",
    "    返回 input_tensor, 缩放比例, padding 偏移\n",
    "    \"\"\"\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "    target_w, target_h = 640,640\n",
    "    scale = min(target_w / orig_w, target_h / orig_h)\n",
    "\n",
    "    new_w = int(orig_w * scale)\n",
    "    new_h = int(orig_h * scale)\n",
    "    resized = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    pad_w = target_w - new_w\n",
    "    pad_h = target_h - new_h\n",
    "    top = pad_h // 2\n",
    "    bottom = pad_h - top\n",
    "    left = pad_w // 2\n",
    "    right = pad_w - left\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8899a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=cv2.imread(\"/home/sunrise/Project20250627/demo.jpg\")\n",
    "frame=preprocess(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "685616be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_file: str\n",
    "        ) -> None:\n",
    "        # 加载BPU的bin模型, 打印相关参数\n",
    "        # Load the quantized *.bin model and print its parameters\n",
    "        try:\n",
    "            begin_time = time.time()\n",
    "            self.quantize_model = dnn.load(model_file)\n",
    "            logger.debug(\"\\033[1;31m\" + \"Load D-Robotics Quantize model time = %.2f ms\"%(1000*(time.time() - begin_time)) + \"\\033[0m\")\n",
    "        except Exception as e:\n",
    "            logger.error(\"❌ Failed to load model file: %s\"%(model_file))\n",
    "            logger.error(\"You can download the model file from the following docs: ./models/download.md\") \n",
    "            logger.error(e)\n",
    "            exit(1)\n",
    "\n",
    "        logger.info(\"\\033[1;32m\" + \"-> input tensors\" + \"\\033[0m\")\n",
    "        for i, quantize_input in enumerate(self.quantize_model[0].inputs):\n",
    "            logger.info(f\"intput[{i}], name={quantize_input.name}, type={quantize_input.properties.dtype}, shape={quantize_input.properties.shape}\")\n",
    "\n",
    "        logger.info(\"\\033[1;32m\" + \"-> output tensors\" + \"\\033[0m\")\n",
    "        for i, quantize_input in enumerate(self.quantize_model[0].outputs):\n",
    "            logger.info(f\"output[{i}], name={quantize_input.name}, type={quantize_input.properties.dtype}, shape={quantize_input.properties.shape}\")\n",
    "\n",
    "        self.model_input_height, self.model_input_weight = self.quantize_model[0].inputs[0].properties.shape[2:4]\n",
    "\n",
    "    def resizer(self, img: np.ndarray)->np.ndarray:\n",
    "        img_h, img_w = img.shape[0:2]\n",
    "        self.y_scale, self.x_scale = img_h/self.model_input_height, img_w/self.model_input_weight\n",
    "        return cv2.resize(img, (self.model_input_height, self.model_input_weight), interpolation=cv2.INTER_NEAREST) # 利用resize重新开辟内存\n",
    "    \n",
    "    def preprocess(self, img: np.ndarray)->np.array:\n",
    "        \"\"\"\n",
    "        Preprocesses an input image to prepare it for model inference.\n",
    "\n",
    "        Args:\n",
    "            img (np.ndarray): The input image in BGR format as a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The preprocessed image tensor in NCHW format ready for model input.\n",
    "\n",
    "        Procedure:\n",
    "            1. Resizes the image to a specified dimension (`input_image_size`) using nearest neighbor interpolation.\n",
    "            2. Converts the image color space from BGR to RGB.\n",
    "            3. Transposes the dimensions of the image tensor to channel-first order (CHW).\n",
    "            4. Adds a batch dimension, thus conforming to the NCHW format expected by many models.\n",
    "            Note: Normalization to [0, 1] is assumed to be handled elsewhere based on configuration.\n",
    "        \"\"\"\n",
    "        begin_time = time.time()\n",
    "\n",
    "        input_tensor = self.resizer(img)\n",
    "        input_tensor = cv2.cvtColor(input_tensor, cv2.COLOR_BGR2RGB)\n",
    "        # input_tensor = np.array(input_tensor) / 255.0  # yaml文件中已经配置前处理\n",
    "        input_tensor = np.transpose(input_tensor, (2, 0, 1))\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=0).astype(np.uint8)  # NCHW\n",
    "\n",
    "        logger.debug(\"\\033[1;31m\" + f\"pre process time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return input_tensor\n",
    "\n",
    "    def bgr2nv12(self, bgr_img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert a BGR image to the NV12 format.\n",
    "\n",
    "        NV12 is a common video encoding format where the Y component (luminance) is full resolution,\n",
    "        and the UV components (chrominance) are half-resolution and interleaved. This function first\n",
    "        converts the BGR image to YUV 4:2:0 planar format, then rearranges the UV components to fit\n",
    "        the NV12 format.\n",
    "\n",
    "        Parameters:\n",
    "        bgr_img (np.ndarray): The input BGR image array.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: The converted NV12 format image array.\n",
    "        \"\"\"\n",
    "        begin_time = time.time()\n",
    "        bgr_img = self.resizer(bgr_img)\n",
    "        height, width = bgr_img.shape[0], bgr_img.shape[1]\n",
    "        area = height * width\n",
    "        yuv420p = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YUV_I420).reshape((area * 3 // 2,))\n",
    "        y = yuv420p[:area]\n",
    "        uv_planar = yuv420p[area:].reshape((2, area // 4))\n",
    "        uv_packed = uv_planar.transpose((1, 0)).reshape((area // 2,))\n",
    "        nv12 = np.zeros_like(yuv420p)\n",
    "        nv12[:height * width] = y\n",
    "        nv12[height * width:] = uv_packed\n",
    "\n",
    "        logger.debug(\"\\033[1;31m\" + f\"bgr8 to nv12 time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return nv12\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor: np.array) -> list[dnn.pyDNNTensor]:\n",
    "        begin_time = time.time()\n",
    "        quantize_outputs = self.quantize_model[0].forward(input_tensor)\n",
    "        logger.debug(\"\\033[1;31m\" + f\"forward time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return quantize_outputs\n",
    "\n",
    "\n",
    "    def c2numpy(self, outputs) -> list[np.array]:\n",
    "        begin_time = time.time()\n",
    "        outputs = [dnnTensor.buffer for dnnTensor in outputs]\n",
    "        logger.debug(\"\\033[1;31m\" + f\"c to numpy time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dfda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO11_Detect(BaseModel):\n",
    "    def __init__(self, \n",
    "                model_file: str, \n",
    "                conf: float, \n",
    "                iou: float\n",
    "                ):\n",
    "        super().__init__(model_file)\n",
    "        # 将反量化系数准备好, 只需要准备一次\n",
    "        # prepare the quantize scale, just need to generate once\n",
    "        self.s_bboxes_scale = self.quantize_model[0].outputs[0].properties.scale_data[np.newaxis, :]\n",
    "        self.m_bboxes_scale = self.quantize_model[0].outputs[1].properties.scale_data[np.newaxis, :]\n",
    "        self.l_bboxes_scale = self.quantize_model[0].outputs[2].properties.scale_data[np.newaxis, :]\n",
    "        logger.info(f\"{self.s_bboxes_scale.shape=}, {self.m_bboxes_scale.shape=}, {self.l_bboxes_scale.shape=}\")\n",
    "\n",
    "        # DFL求期望的系数, 只需要生成一次\n",
    "        # DFL calculates the expected coefficients, which only needs to be generated once.\n",
    "        self.weights_static = np.array([i for i in range(16)]).astype(np.float32)[np.newaxis, np.newaxis, :]\n",
    "        logger.info(f\"{self.weights_static.shape = }\")\n",
    "\n",
    "        # anchors, 只需要生成一次\n",
    "        self.s_anchor = np.stack([np.tile(np.linspace(0.5, 79.5, 80), reps=80), \n",
    "                            np.repeat(np.arange(0.5, 80.5, 1), 80)], axis=0).transpose(1,0)\n",
    "        self.m_anchor = np.stack([np.tile(np.linspace(0.5, 39.5, 40), reps=40), \n",
    "                            np.repeat(np.arange(0.5, 40.5, 1), 40)], axis=0).transpose(1,0)\n",
    "        self.l_anchor = np.stack([np.tile(np.linspace(0.5, 19.5, 20), reps=20), \n",
    "                            np.repeat(np.arange(0.5, 20.5, 1), 20)], axis=0).transpose(1,0)\n",
    "        logger.info(f\"{self.s_anchor.shape = }, {self.m_anchor.shape = }, {self.l_anchor.shape = }\")\n",
    "\n",
    "        # 输入图像大小, 一些阈值, 提前计算好\n",
    "        self.input_image_size = 640\n",
    "        self.conf = conf\n",
    "        self.iou = iou\n",
    "        self.conf_inverse = -np.log(1/conf - 1)\n",
    "        logger.info(\"iou threshol = %.2f, conf threshol = %.2f\"%(iou, conf))\n",
    "        logger.info(\"sigmoid_inverse threshol = %.2f\"%self.conf_inverse)\n",
    "    \n",
    "\n",
    "    def postProcess(self, outputs: list[np.ndarray]) -> tuple[list]:\n",
    "        begin_time = time.time()\n",
    "        # reshape\n",
    "        s_bboxes = outputs[0].reshape(-1, 64)\n",
    "        m_bboxes = outputs[1].reshape(-1, 64)\n",
    "        l_bboxes = outputs[2].reshape(-1, 64)\n",
    "        s_clses = outputs[3].reshape(-1, 80)\n",
    "        m_clses = outputs[4].reshape(-1, 80)\n",
    "        l_clses = outputs[5].reshape(-1, 80)\n",
    "\n",
    "        # classify: 利用numpy向量化操作完成阈值筛选(优化版 2.0)\n",
    "        s_max_scores = np.max(s_clses, axis=1)\n",
    "        s_valid_indices = np.flatnonzero(s_max_scores >= self.conf_inverse)  # 得到大于阈值分数的索引，此时为小数字\n",
    "        s_ids = np.argmax(s_clses[s_valid_indices, : ], axis=1)\n",
    "        s_scores = s_max_scores[s_valid_indices]\n",
    "\n",
    "        m_max_scores = np.max(m_clses, axis=1)\n",
    "        m_valid_indices = np.flatnonzero(m_max_scores >= self.conf_inverse)  # 得到大于阈值分数的索引，此时为小数字\n",
    "        m_ids = np.argmax(m_clses[m_valid_indices, : ], axis=1)\n",
    "        m_scores = m_max_scores[m_valid_indices]\n",
    "\n",
    "        l_max_scores = np.max(l_clses, axis=1)\n",
    "        l_valid_indices = np.flatnonzero(l_max_scores >= self.conf_inverse)  # 得到大于阈值分数的索引，此时为小数字\n",
    "        l_ids = np.argmax(l_clses[l_valid_indices, : ], axis=1)\n",
    "        l_scores = l_max_scores[l_valid_indices]\n",
    "\n",
    "        # 3个Classify分类分支：Sigmoid计算\n",
    "        s_scores = 1 / (1 + np.exp(-s_scores))\n",
    "        m_scores = 1 / (1 + np.exp(-m_scores))\n",
    "        l_scores = 1 / (1 + np.exp(-l_scores))\n",
    "\n",
    "        # 3个Bounding Box分支：筛选\n",
    "        s_bboxes_float32 = s_bboxes[s_valid_indices,:]#.astype(np.float32) * self.s_bboxes_scale\n",
    "        m_bboxes_float32 = m_bboxes[m_valid_indices,:]#.astype(np.float32) * self.m_bboxes_scale\n",
    "        l_bboxes_float32 = l_bboxes[l_valid_indices,:]#.astype(np.float32) * self.l_bboxes_scale\n",
    "\n",
    "        # 3个Bounding Box分支：dist2bbox (ltrb2xyxy)\n",
    "        s_ltrb_indices = np.sum(softmax(s_bboxes_float32.reshape(-1, 4, 16), axis=2) * self.weights_static, axis=2)\n",
    "        s_anchor_indices = self.s_anchor[s_valid_indices, :]\n",
    "        s_x1y1 = s_anchor_indices - s_ltrb_indices[:, 0:2]\n",
    "        s_x2y2 = s_anchor_indices + s_ltrb_indices[:, 2:4]\n",
    "        s_dbboxes = np.hstack([s_x1y1, s_x2y2])*8\n",
    "\n",
    "        m_ltrb_indices = np.sum(softmax(m_bboxes_float32.reshape(-1, 4, 16), axis=2) * self.weights_static, axis=2)\n",
    "        m_anchor_indices = self.m_anchor[m_valid_indices, :]\n",
    "        m_x1y1 = m_anchor_indices - m_ltrb_indices[:, 0:2]\n",
    "        m_x2y2 = m_anchor_indices + m_ltrb_indices[:, 2:4]\n",
    "        m_dbboxes = np.hstack([m_x1y1, m_x2y2])*16\n",
    "\n",
    "        l_ltrb_indices = np.sum(softmax(l_bboxes_float32.reshape(-1, 4, 16), axis=2) * self.weights_static, axis=2)\n",
    "        l_anchor_indices = self.l_anchor[l_valid_indices,:]\n",
    "        l_x1y1 = l_anchor_indices - l_ltrb_indices[:, 0:2]\n",
    "        l_x2y2 = l_anchor_indices + l_ltrb_indices[:, 2:4]\n",
    "        l_dbboxes = np.hstack([l_x1y1, l_x2y2])*32\n",
    "\n",
    "        # 大中小特征层阈值筛选结果拼接\n",
    "        dbboxes = np.concatenate((s_dbboxes, m_dbboxes, l_dbboxes), axis=0)\n",
    "        scores = np.concatenate((s_scores, m_scores, l_scores), axis=0)\n",
    "        ids = np.concatenate((s_ids, m_ids, l_ids), axis=0)\n",
    "\n",
    "        # nms\n",
    "        indices = cv2.dnn.NMSBoxes(dbboxes, scores, self.conf, self.iou)\n",
    "\n",
    "        # 还原到原始的img尺度\n",
    "        bboxes = dbboxes[indices] * np.array([self.x_scale, self.y_scale, self.x_scale, self.y_scale])\n",
    "        bboxes = bboxes.astype(np.int32)\n",
    "\n",
    "        logger.debug(\"\\033[1;31m\" + f\"Post Process time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "        return ids[indices], scores[indices], bboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63ef461",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '[%(name)s] [%(asctime)s.%(msecs)03d] [%(levelname)s] %(message)s',\n",
    "    datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(\"RDK_YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc403f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RDK_YOLO] [11:42:02.053] [DEBUG] \u001b[1;31mLoad D-Robotics Quantize model time = 128.85 ms\u001b[0m\n",
      "[RDK_YOLO] [11:42:02.057] [INFO] \u001b[1;32m-> input tensors\u001b[0m\n",
      "[RDK_YOLO] [11:42:02.059] [INFO] intput[0], name=images, type=uint8, shape=(1, 3, 640, 640)\n",
      "[RDK_YOLO] [11:42:02.062] [INFO] \u001b[1;32m-> output tensors\u001b[0m\n",
      "[RDK_YOLO] [11:42:02.064] [INFO] output[0], name=small, type=float32, shape=(1, 80, 80, 18)\n",
      "[RDK_YOLO] [11:42:02.067] [INFO] output[1], name=medium, type=float32, shape=(1, 40, 40, 18)\n",
      "[RDK_YOLO] [11:42:02.070] [INFO] output[2], name=big, type=float32, shape=(1, 20, 20, 18)\n",
      "[RDK_YOLO] [11:42:02.073] [INFO] self.s_bboxes_scale.shape=(1, 0), self.m_bboxes_scale.shape=(1, 0), self.l_bboxes_scale.shape=(1, 0)\n",
      "[RDK_YOLO] [11:42:02.076] [INFO] self.weights_static.shape = (1, 1, 16)\n",
      "[RDK_YOLO] [11:42:02.088] [INFO] self.s_anchor.shape = (6400, 2), self.m_anchor.shape = (1600, 2), self.l_anchor.shape = (400, 2)\n",
      "[RDK_YOLO] [11:42:02.091] [INFO] iou threshol = 0.45, conf threshol = 0.25\n",
      "[RDK_YOLO] [11:42:02.094] [INFO] sigmoid_inverse threshol = -1.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W][DNN]packed_model.cpp:114][Model](2025-06-27,11:42:02.52.264) File /home/sunrise/Project20250627/Chili.bin has loaded, Discard the latest. \n"
     ]
    }
   ],
   "source": [
    "model_path=\"/home/sunrise/Project20250627/Chili.bin\"\n",
    "iou_thres=0.45\n",
    "conf_thres=0.25\n",
    "classes_num=1\n",
    "reg=16\n",
    "model = YOLO11_Detect(model_path, conf_thres, iou_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff95b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RDK_YOLO] [11:42:14.110] [DEBUG] \u001b[1;31mbgr8 to nv12 time = 5.78 ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "s_anchor = np.stack([np.tile(np.linspace(0.5, 79.5, 80), reps=80), \n",
    "                        np.repeat(np.arange(0.5, 80.5, 1), 80)], axis=0).transpose(1,0)\n",
    "m_anchor = np.stack([np.tile(np.linspace(0.5, 39.5, 40), reps=40), \n",
    "                            np.repeat(np.arange(0.5, 40.5, 1), 40)], axis=0).transpose(1,0)\n",
    "l_anchor = np.stack([np.tile(np.linspace(0.5, 19.5, 20), reps=20), \n",
    "                            np.repeat(np.arange(0.5, 20.5, 1), 20)], axis=0).transpose(1,0)\n",
    "input_tensor=model.bgr2nv12(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0048eca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RDK_YOLO] [11:42:36.222] [DEBUG] \u001b[1;31mforward time = 18.45 ms\u001b[0m\n",
      "[RDK_YOLO] [11:42:36.227] [DEBUG] \u001b[1;31mc to numpy time = 0.62 ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "outputs = model.c2numpy(model.forward(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3001716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 20, 18)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7bb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def postprocess_yolov5s_output(output, conf_thres=0.25, iou_thres=0.45, input_size=640, anchors=None):\n",
    "    \"\"\"\n",
    "    NumPy 版本的 YOLOv5 后处理（单层）\n",
    "    参数:\n",
    "        output: ndarray, shape (1, 80, 80, 18)\n",
    "        anchors: list or array, [[w1,h1], [w2,h2], [w3,h3]]\n",
    "    返回:\n",
    "        list of [x1, y1, x2, y2, confidence]\n",
    "    \"\"\"\n",
    "    if anchors is None:\n",
    "        anchors = np.array([[10,13], [16,30], [33,23]])  # 默认 anchor\n",
    "\n",
    "    stride = input_size // output.shape[1]  # 640 / 80 = 8\n",
    "    output = output.reshape(1, 80, 80, 3, 6)  # [1, 80, 80, 3, 6]\n",
    "    output = output[0]  # [80, 80, 3, 6]\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for y in range(80):\n",
    "        for x in range(80):\n",
    "            for a in range(3):\n",
    "                tx, ty, tw, th, obj, cls = output[y, x, a]\n",
    "\n",
    "                obj = sigmoid(obj)\n",
    "                cls = sigmoid(cls)\n",
    "                score = obj * cls\n",
    "                if score < conf_thres:\n",
    "                    continue\n",
    "\n",
    "                anchor_w, anchor_h = anchors[a]\n",
    "\n",
    "                # 解码回原图坐标\n",
    "                cx = (sigmoid(tx) + x) * stride\n",
    "                cy = (sigmoid(ty) + y) * stride\n",
    "                w = np.exp(tw) * anchor_w\n",
    "                h = np.exp(th) * anchor_h\n",
    "\n",
    "                x1 = cx - w / 2\n",
    "                y1 = cy - h / 2\n",
    "                x2 = cx + w / 2\n",
    "                y2 = cy + h / 2\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2, score])\n",
    "\n",
    "    return nms(np.array(boxes), iou_thres)\n",
    "\n",
    "def nms(boxes, iou_threshold):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = boxes[np.argsort(-boxes[:, 4])]  # 按 score 降序排序\n",
    "    keep = []\n",
    "\n",
    "    while len(boxes) > 0:\n",
    "        best = boxes[0]\n",
    "        keep.append(best)\n",
    "        rest = boxes[1:]\n",
    "\n",
    "        ious = compute_iou_batch(best, rest)\n",
    "        boxes = rest[ious < iou_threshold]\n",
    "\n",
    "    return keep\n",
    "\n",
    "def compute_iou_batch(box1, boxes):\n",
    "    \"\"\"\n",
    "    box1: shape (5,)  [x1, y1, x2, y2, conf]\n",
    "    boxes: shape (N, 5)\n",
    "    return: shape (N,) 的 IoU 数组\n",
    "    \"\"\"\n",
    "    x1 = np.maximum(box1[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box1[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box1[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box1[3], boxes[:, 3])\n",
    "\n",
    "    inter_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = area1 + area2 - inter_area\n",
    "\n",
    "    iou = inter_area / (union_area + 1e-6)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e1aa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=postprocess_yolov5s_output(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98ca4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBox: (75.9, 215.4) → (109.6, 272.1), Confidence: 0.68\n"
     ]
    }
   ],
   "source": [
    "for box in results:\n",
    "    x1, y1, x2, y2, conf = box\n",
    "    print(f\"BBox: ({x1:.1f}, {y1:.1f}) → ({x2:.1f}, {y2:.1f}), Confidence: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6661ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_bboxes(frame, results, color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    在图像上绘制边框和置信度分数\n",
    "    :param frame: 原始图像 (BGR 格式)\n",
    "    :param results: 检测结果 [[x1, y1, x2, y2, conf], ...]\n",
    "    :param color: 边框颜色，默认绿色\n",
    "    :return: 带框图像\n",
    "    \"\"\"\n",
    "    for box in results:\n",
    "        x1, y1, x2, y2, conf = box\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, f\"{conf:.2f}\", (x1, y1 - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db245866",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = draw_bboxes(frame, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0903f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"/home/sunrise/Project20250627/render.jpg\",frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a8b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
