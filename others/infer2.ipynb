{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9d85b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "# from scipy.special import expit as sigmoid\n",
    "from hobot_dnn import pyeasy_dnn as dnn  # BSP Python API\n",
    "import time\n",
    "import argparse\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68ac0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_info(content, log_file=\"log.txt\"):\n",
    "    \"\"\"\n",
    "    记录并打印日志信息\n",
    "    :param content: 日志内容\n",
    "    :param log_file: 日志文件路径，默认为当前目录下的 log.txt\n",
    "    \"\"\"\n",
    "    # 获取当前时间\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    \n",
    "    # 格式化日志信息\n",
    "    log_message = f\"[{current_time}] {content}\"\n",
    "    \n",
    "    # 打印日志到控制台\n",
    "    print(log_message)\n",
    "    \n",
    "    # 将日志写入文件\n",
    "    # with open(log_file, \"a\", encoding=\"utf-8\") as file:\n",
    "    #     file.write(log_message + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a60bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    \"\"\"\n",
    "    预处理图像：letterbox 缩放 + padding\n",
    "    返回 input_tensor, 缩放比例, padding 偏移\n",
    "    \"\"\"\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "    target_w, target_h = 640,640\n",
    "    scale = min(target_w / orig_w, target_h / orig_h)\n",
    "\n",
    "    new_w = int(orig_w * scale)\n",
    "    new_h = int(orig_h * scale)\n",
    "    resized = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    pad_w = target_w - new_w\n",
    "    pad_h = target_h - new_h\n",
    "    top = pad_h // 2\n",
    "    bottom = pad_h - top\n",
    "    left = pad_w // 2\n",
    "    right = pad_w - left\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81ffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_file: str\n",
    "        ) -> None:\n",
    "        # 加载BPU的bin模型, 打印相关参数\n",
    "        # Load the quantized *.bin model and print its parameters\n",
    "        try:\n",
    "            begin_time = time.time()\n",
    "            self.quantize_model = dnn.load(model_file)\n",
    "            logger.debug(\"\\033[1;31m\" + \"Load D-Robotics Quantize model time = %.2f ms\"%(1000*(time.time() - begin_time)) + \"\\033[0m\")\n",
    "        except Exception as e:\n",
    "            logger.error(\"❌ Failed to load model file: %s\"%(model_file))\n",
    "            logger.error(\"You can download the model file from the following docs: ./models/download.md\") \n",
    "            logger.error(e)\n",
    "            exit(1)\n",
    "\n",
    "        logger.info(\"\\033[1;32m\" + \"-> input tensors\" + \"\\033[0m\")\n",
    "        for i, quantize_input in enumerate(self.quantize_model[0].inputs):\n",
    "            logger.info(f\"intput[{i}], name={quantize_input.name}, type={quantize_input.properties.dtype}, shape={quantize_input.properties.shape}\")\n",
    "\n",
    "        logger.info(\"\\033[1;32m\" + \"-> output tensors\" + \"\\033[0m\")\n",
    "        for i, quantize_input in enumerate(self.quantize_model[0].outputs):\n",
    "            logger.info(f\"output[{i}], name={quantize_input.name}, type={quantize_input.properties.dtype}, shape={quantize_input.properties.shape}\")\n",
    "\n",
    "        self.model_input_height, self.model_input_weight = self.quantize_model[0].inputs[0].properties.shape[2:4]\n",
    "\n",
    "    def resizer(self, img: np.ndarray)->np.ndarray:\n",
    "        img_h, img_w = img.shape[0:2]\n",
    "        self.y_scale, self.x_scale = img_h/self.model_input_height, img_w/self.model_input_weight\n",
    "        return cv2.resize(img, (self.model_input_height, self.model_input_weight), interpolation=cv2.INTER_NEAREST) # 利用resize重新开辟内存\n",
    "    \n",
    "    def preprocess(self, img: np.ndarray)->np.array:\n",
    "        \"\"\"\n",
    "        Preprocesses an input image to prepare it for model inference.\n",
    "\n",
    "        Args:\n",
    "            img (np.ndarray): The input image in BGR format as a NumPy array.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The preprocessed image tensor in NCHW format ready for model input.\n",
    "\n",
    "        Procedure:\n",
    "            1. Resizes the image to a specified dimension (`input_image_size`) using nearest neighbor interpolation.\n",
    "            2. Converts the image color space from BGR to RGB.\n",
    "            3. Transposes the dimensions of the image tensor to channel-first order (CHW).\n",
    "            4. Adds a batch dimension, thus conforming to the NCHW format expected by many models.\n",
    "            Note: Normalization to [0, 1] is assumed to be handled elsewhere based on configuration.\n",
    "        \"\"\"\n",
    "        begin_time = time.time()\n",
    "\n",
    "        input_tensor = self.resizer(img)\n",
    "        input_tensor = cv2.cvtColor(input_tensor, cv2.COLOR_BGR2RGB)\n",
    "        # input_tensor = np.array(input_tensor) / 255.0  # yaml文件中已经配置前处理\n",
    "        input_tensor = np.transpose(input_tensor, (2, 0, 1))\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=0).astype(np.uint8)  # NCHW\n",
    "\n",
    "        logger.debug(\"\\033[1;31m\" + f\"pre process time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return input_tensor\n",
    "\n",
    "    def bgr2nv12(self, bgr_img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert a BGR image to the NV12 format.\n",
    "\n",
    "        NV12 is a common video encoding format where the Y component (luminance) is full resolution,\n",
    "        and the UV components (chrominance) are half-resolution and interleaved. This function first\n",
    "        converts the BGR image to YUV 4:2:0 planar format, then rearranges the UV components to fit\n",
    "        the NV12 format.\n",
    "\n",
    "        Parameters:\n",
    "        bgr_img (np.ndarray): The input BGR image array.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: The converted NV12 format image array.\n",
    "        \"\"\"\n",
    "        begin_time = time.time()\n",
    "        bgr_img = self.resizer(bgr_img)\n",
    "        height, width = bgr_img.shape[0], bgr_img.shape[1]\n",
    "        area = height * width\n",
    "        yuv420p = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YUV_I420).reshape((area * 3 // 2,))\n",
    "        y = yuv420p[:area]\n",
    "        uv_planar = yuv420p[area:].reshape((2, area // 4))\n",
    "        uv_packed = uv_planar.transpose((1, 0)).reshape((area // 2,))\n",
    "        nv12 = np.zeros_like(yuv420p)\n",
    "        nv12[:height * width] = y\n",
    "        nv12[height * width:] = uv_packed\n",
    "\n",
    "        logger.debug(\"\\033[1;31m\" + f\"bgr8 to nv12 time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return nv12\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor: np.array) -> list[dnn.pyDNNTensor]:\n",
    "        begin_time = time.time()\n",
    "        quantize_outputs = self.quantize_model[0].forward(input_tensor)\n",
    "        logger.debug(\"\\033[1;31m\" + f\"forward time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return quantize_outputs\n",
    "\n",
    "\n",
    "    def c2numpy(self, outputs) -> list[np.array]:\n",
    "        begin_time = time.time()\n",
    "        outputs = [dnnTensor.buffer for dnnTensor in outputs]\n",
    "        logger.debug(\"\\033[1;31m\" + f\"c to numpy time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f26d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO11_Detect(BaseModel):\n",
    "    def __init__(self, \n",
    "                model_file: str, \n",
    "                conf: float, \n",
    "                iou: float\n",
    "                ):\n",
    "        super().__init__(model_file)\n",
    "        # 将反量化系数准备好, 只需要准备一次\n",
    "        # prepare the quantize scale, just need to generate once\n",
    "        self.s_bboxes_scale = self.quantize_model[0].outputs[0].properties.scale_data[np.newaxis, :]\n",
    "        self.m_bboxes_scale = self.quantize_model[0].outputs[1].properties.scale_data[np.newaxis, :]\n",
    "        self.l_bboxes_scale = self.quantize_model[0].outputs[2].properties.scale_data[np.newaxis, :]\n",
    "        logger.info(f\"{self.s_bboxes_scale.shape=}, {self.m_bboxes_scale.shape=}, {self.l_bboxes_scale.shape=}\")\n",
    "\n",
    "        # DFL求期望的系数, 只需要生成一次\n",
    "        # DFL calculates the expected coefficients, which only needs to be generated once.\n",
    "        self.weights_static = np.array([i for i in range(16)]).astype(np.float32)[np.newaxis, np.newaxis, :]\n",
    "        logger.info(f\"{self.weights_static.shape = }\")\n",
    "\n",
    "        # anchors, 只需要生成一次\n",
    "        self.s_anchor = np.stack([np.tile(np.linspace(0.5, 79.5, 80), reps=80), \n",
    "                            np.repeat(np.arange(0.5, 80.5, 1), 80)], axis=0).transpose(1,0)\n",
    "        self.m_anchor = np.stack([np.tile(np.linspace(0.5, 39.5, 40), reps=40), \n",
    "                            np.repeat(np.arange(0.5, 40.5, 1), 40)], axis=0).transpose(1,0)\n",
    "        self.l_anchor = np.stack([np.tile(np.linspace(0.5, 19.5, 20), reps=20), \n",
    "                            np.repeat(np.arange(0.5, 20.5, 1), 20)], axis=0).transpose(1,0)\n",
    "        logger.info(f\"{self.s_anchor.shape = }, {self.m_anchor.shape = }, {self.l_anchor.shape = }\")\n",
    "\n",
    "        # 输入图像大小, 一些阈值, 提前计算好\n",
    "        self.input_image_size = 640\n",
    "        self.conf = conf\n",
    "        self.iou = iou\n",
    "        self.conf_inverse = -np.log(1/conf - 1)\n",
    "        logger.info(\"iou threshol = %.2f, conf threshol = %.2f\"%(iou, conf))\n",
    "        logger.info(\"sigmoid_inverse threshol = %.2f\"%self.conf_inverse)\n",
    "    \n",
    "\n",
    "    def postProcess(self, outputs: list[np.ndarray]) -> tuple[list]:\n",
    "        begin_time = time.time()\n",
    "        # reshape\n",
    "        s_bboxes = outputs[0].reshape(-1, 64)\n",
    "        m_bboxes = outputs[1].reshape(-1, 64)\n",
    "        l_bboxes = outputs[2].reshape(-1, 64)\n",
    "        s_clses = outputs[3].reshape(-1, 80)\n",
    "        m_clses = outputs[4].reshape(-1, 80)\n",
    "        l_clses = outputs[5].reshape(-1, 80)\n",
    "\n",
    "        # classify: 利用numpy向量化操作完成阈值筛选(优化版 2.0)\n",
    "        s_max_scores = np.max(s_clses, axis=1)\n",
    "        s_valid_indices = np.flatnonzero(s_max_scores >= self.conf_inverse)  # 得到大于阈值分数的索引，此时为小数字\n",
    "        s_ids = np.argmax(s_clses[s_valid_indices, : ], axis=1)\n",
    "        s_scores = s_max_scores[s_valid_indices]\n",
    "\n",
    "        m_max_scores = np.max(m_clses, axis=1)\n",
    "        m_valid_indices = np.flatnonzero(m_max_scores >= self.conf_inverse)  # 得到大于阈值分数的索引，此时为小数字\n",
    "        m_ids = np.argmax(m_clses[m_valid_indices, : ], axis=1)\n",
    "        m_scores = m_max_scores[m_valid_indices]\n",
    "\n",
    "        l_max_scores = np.max(l_clses, axis=1)\n",
    "        l_valid_indices = np.flatnonzero(l_max_scores >= self.conf_inverse)  # 得到大于阈值分数的索引，此时为小数字\n",
    "        l_ids = np.argmax(l_clses[l_valid_indices, : ], axis=1)\n",
    "        l_scores = l_max_scores[l_valid_indices]\n",
    "\n",
    "        # 3个Classify分类分支：Sigmoid计算\n",
    "        s_scores = 1 / (1 + np.exp(-s_scores))\n",
    "        m_scores = 1 / (1 + np.exp(-m_scores))\n",
    "        l_scores = 1 / (1 + np.exp(-l_scores))\n",
    "\n",
    "        # 3个Bounding Box分支：筛选\n",
    "        s_bboxes_float32 = s_bboxes[s_valid_indices,:]#.astype(np.float32) * self.s_bboxes_scale\n",
    "        m_bboxes_float32 = m_bboxes[m_valid_indices,:]#.astype(np.float32) * self.m_bboxes_scale\n",
    "        l_bboxes_float32 = l_bboxes[l_valid_indices,:]#.astype(np.float32) * self.l_bboxes_scale\n",
    "\n",
    "        # 3个Bounding Box分支：dist2bbox (ltrb2xyxy)\n",
    "        s_ltrb_indices = np.sum(softmax(s_bboxes_float32.reshape(-1, 4, 16), axis=2) * self.weights_static, axis=2)\n",
    "        s_anchor_indices = self.s_anchor[s_valid_indices, :]\n",
    "        s_x1y1 = s_anchor_indices - s_ltrb_indices[:, 0:2]\n",
    "        s_x2y2 = s_anchor_indices + s_ltrb_indices[:, 2:4]\n",
    "        s_dbboxes = np.hstack([s_x1y1, s_x2y2])*8\n",
    "\n",
    "        m_ltrb_indices = np.sum(softmax(m_bboxes_float32.reshape(-1, 4, 16), axis=2) * self.weights_static, axis=2)\n",
    "        m_anchor_indices = self.m_anchor[m_valid_indices, :]\n",
    "        m_x1y1 = m_anchor_indices - m_ltrb_indices[:, 0:2]\n",
    "        m_x2y2 = m_anchor_indices + m_ltrb_indices[:, 2:4]\n",
    "        m_dbboxes = np.hstack([m_x1y1, m_x2y2])*16\n",
    "\n",
    "        l_ltrb_indices = np.sum(softmax(l_bboxes_float32.reshape(-1, 4, 16), axis=2) * self.weights_static, axis=2)\n",
    "        l_anchor_indices = self.l_anchor[l_valid_indices,:]\n",
    "        l_x1y1 = l_anchor_indices - l_ltrb_indices[:, 0:2]\n",
    "        l_x2y2 = l_anchor_indices + l_ltrb_indices[:, 2:4]\n",
    "        l_dbboxes = np.hstack([l_x1y1, l_x2y2])*32\n",
    "\n",
    "        # 大中小特征层阈值筛选结果拼接\n",
    "        dbboxes = np.concatenate((s_dbboxes, m_dbboxes, l_dbboxes), axis=0)\n",
    "        scores = np.concatenate((s_scores, m_scores, l_scores), axis=0)\n",
    "        ids = np.concatenate((s_ids, m_ids, l_ids), axis=0)\n",
    "\n",
    "        # nms\n",
    "        indices = cv2.dnn.NMSBoxes(dbboxes, scores, self.conf, self.iou)\n",
    "\n",
    "        # 还原到原始的img尺度\n",
    "        bboxes = dbboxes[indices] * np.array([self.x_scale, self.y_scale, self.x_scale, self.y_scale])\n",
    "        bboxes = bboxes.astype(np.int32)\n",
    "\n",
    "        logger.debug(\"\\033[1;31m\" + f\"Post Process time = {1000*(time.time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "        return ids[indices], scores[indices], bboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296022b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "def post_process(outputs, anchors, strides, weights_static, conf_thres=0.25, iou_thres=0.5, scale_factors=(1.0, 1.0)):\n",
    "    \"\"\"\n",
    "    outputs: list of 6 np.ndarray:\n",
    "        [0] (1, 80, 80, 64), [1] (1, 40, 40, 64), [2] (1, 20, 20, 64) -- bbox\n",
    "        [3] (1, 80, 80, 1),  [4] (1, 40, 40, 1),  [5] (1, 20, 20, 1)  -- cls (1类)\n",
    "    anchors: list of 3 (N, 2) arrays for s/m/l anchor center coords\n",
    "    strides: list of 3 stride ints, e.g. [8, 16, 32]\n",
    "    weights_static: (1, 16) array for bbox解码 softmax 加权\n",
    "    \"\"\"\n",
    "\n",
    "    dbboxes_all, scores_all = [], []\n",
    "\n",
    "    for i in range(3):  # 遍历三个特征层\n",
    "        bbox_pred = outputs[i].reshape(-1, 64)         # shape: (H*W*A, 64)\n",
    "        cls_pred = outputs[i + 3].reshape(-1, 1)       # shape: (H*W*A, 1)\n",
    "        anchors_grid = anchors[i]                     # shape: (H*W*A, 2)\n",
    "        stride = strides[i]\n",
    "\n",
    "        # 分类得分（Sigmoid + 阈值）\n",
    "        scores = sigmoid(cls_pred.squeeze())          # shape: (N,)\n",
    "        valid_mask = scores >= conf_thres\n",
    "        if np.sum(valid_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        bbox_valid = bbox_pred[valid_mask]\n",
    "        scores_valid = scores[valid_mask]\n",
    "        anchors_valid = anchors_grid[valid_mask]\n",
    "\n",
    "        # bbox解码：reshape为 (N, 4, 16)，softmax → weighted sum\n",
    "        ltrb_distri = bbox_valid.reshape(-1, 4, 16)\n",
    "        ltrb = np.sum(softmax(ltrb_distri, axis=2) * weights_static, axis=2)\n",
    "\n",
    "        # 解码得到 x1, y1, x2, y2（ltrb 相对 anchor 中心）\n",
    "        x1y1 = anchors_valid - ltrb[:, :2]\n",
    "        x2y2 = anchors_valid + ltrb[:, 2:]\n",
    "        boxes = np.hstack([x1y1, x2y2]) * stride\n",
    "\n",
    "        dbboxes_all.append(boxes)\n",
    "        scores_all.append(scores_valid)\n",
    "\n",
    "    if not dbboxes_all:\n",
    "        return [], [], []\n",
    "\n",
    "    dbboxes_all = np.concatenate(dbboxes_all, axis=0)\n",
    "    scores_all = np.concatenate(scores_all, axis=0)\n",
    "    ids_all = np.zeros_like(scores_all, dtype=int)  # 全是0类\n",
    "\n",
    "    # NMS：OpenCV 格式是 [x, y, w, h]\n",
    "    xywh = dbboxes_all.copy()\n",
    "    xywh[:, 2:] -= xywh[:, :2]  # 转换为 w, h\n",
    "\n",
    "    nms_indices = cv2.dnn.NMSBoxes(\n",
    "        bboxes=xywh.tolist(), scores=scores_all.tolist(),\n",
    "        score_threshold=conf_thres, nms_threshold=iou_thres\n",
    "    )\n",
    "\n",
    "    if len(nms_indices) == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    nms_indices = np.array(nms_indices).flatten()\n",
    "\n",
    "    x_scale, y_scale = scale_factors\n",
    "    scale = np.array([x_scale, y_scale, x_scale, y_scale])\n",
    "    final_boxes = dbboxes_all[nms_indices] * scale\n",
    "    final_boxes = final_boxes.astype(np.int32)\n",
    "\n",
    "    return ids_all[nms_indices], scores_all[nms_indices], final_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8e21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '[%(name)s] [%(asctime)s.%(msecs)03d] [%(levelname)s] %(message)s',\n",
    "    datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(\"RDK_YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353d3f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RDK_YOLO] [11:58:56.570] [DEBUG] \u001b[1;31mLoad D-Robotics Quantize model time = 297.32 ms\u001b[0m\n",
      "[RDK_YOLO] [11:58:56.574] [INFO] \u001b[1;32m-> input tensors\u001b[0m\n",
      "[RDK_YOLO] [11:58:56.577] [INFO] intput[0], name=images, type=uint8, shape=(1, 3, 640, 640)\n",
      "[RDK_YOLO] [11:58:56.579] [INFO] \u001b[1;32m-> output tensors\u001b[0m\n",
      "[RDK_YOLO] [11:58:56.582] [INFO] output[0], name=small, type=float32, shape=(1, 80, 80, 18)\n",
      "[RDK_YOLO] [11:58:56.585] [INFO] output[1], name=medium, type=float32, shape=(1, 40, 40, 18)\n",
      "[RDK_YOLO] [11:58:56.588] [INFO] output[2], name=big, type=float32, shape=(1, 20, 20, 18)\n",
      "[RDK_YOLO] [11:58:56.591] [INFO] self.s_bboxes_scale.shape=(1, 0), self.m_bboxes_scale.shape=(1, 0), self.l_bboxes_scale.shape=(1, 0)\n",
      "[RDK_YOLO] [11:58:56.594] [INFO] self.weights_static.shape = (1, 1, 16)\n",
      "[RDK_YOLO] [11:58:56.601] [INFO] self.s_anchor.shape = (6400, 2), self.m_anchor.shape = (1600, 2), self.l_anchor.shape = (400, 2)\n",
      "[RDK_YOLO] [11:58:56.603] [INFO] iou threshol = 0.45, conf threshol = 0.25\n",
      "[RDK_YOLO] [11:58:56.606] [INFO] sigmoid_inverse threshol = -1.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BPU_PLAT]BPU Platform Version(1.3.6)!\n",
      "[HBRT] set log level as 0. version = 3.15.55.0\n",
      "[DNN] Runtime version = 1.24.5_(3.15.55 HBRT)\n",
      "[A][DNN][packed_model.cpp:247][Model](2025-06-27,11:58:56.456.810) [HorizonRT] The model builder version = 1.24.3\n"
     ]
    }
   ],
   "source": [
    "model_path=\"/home/sunrise/Project20250627/Chili.bin\"\n",
    "iou_thres=0.45\n",
    "conf_thres=0.25\n",
    "classes_num=1\n",
    "reg=16\n",
    "model = YOLO11_Detect(model_path, conf_thres, iou_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0bded9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_anchor = np.stack([np.tile(np.linspace(0.5, 79.5, 80), reps=80), \n",
    "                        np.repeat(np.arange(0.5, 80.5, 1), 80)], axis=0).transpose(1,0)\n",
    "m_anchor = np.stack([np.tile(np.linspace(0.5, 39.5, 40), reps=40), \n",
    "                            np.repeat(np.arange(0.5, 40.5, 1), 40)], axis=0).transpose(1,0)\n",
    "l_anchor = np.stack([np.tile(np.linspace(0.5, 19.5, 20), reps=20), \n",
    "                            np.repeat(np.arange(0.5, 20.5, 1), 20)], axis=0).transpose(1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "492bce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=cv2.imread(\"/home/sunrise/Project20250627/demo2.jpg\")\n",
    "frame=preprocess(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1e54c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RDK_YOLO] [12:07:35.207] [DEBUG] \u001b[1;31mbgr8 to nv12 time = 8.14 ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_tensor=model.bgr2nv12(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b868b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[RDK_YOLO] [12:07:36.106] [DEBUG] \u001b[1;31mforward time = 11.55 ms\u001b[0m\n",
      "[RDK_YOLO] [12:07:36.118] [DEBUG] \u001b[1;31mc to numpy time = 0.34 ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "outputs = model.c2numpy(model.forward(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7fa2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80, 80, 18)\n",
      "(1, 40, 40, 18)\n",
      "(1, 20, 20, 18)\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebb3474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def decode_layer(output, anchors, stride, conf_thres):\n",
    "    \"\"\"\n",
    "    单个输出层的解码逻辑\n",
    "    output: shape (1, h, w, 18)\n",
    "    anchors: shape (3, 2), 对应 3 个 anchor 尺寸\n",
    "    stride: 缩放倍数（8、16、32）\n",
    "    \"\"\"\n",
    "    h, w = output.shape[1], output.shape[2]\n",
    "    output = output.reshape(h, w, 3, 6)  # 每个 grid cell 有 3 个 anchor，每个 anchor 6 个值\n",
    "    boxes = []\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            for a in range(3):\n",
    "                tx, ty, tw, th, obj, cls = output[y, x, a]\n",
    "\n",
    "                obj = sigmoid(obj)\n",
    "                cls = sigmoid(cls)\n",
    "                conf = obj * cls\n",
    "                if conf < conf_thres:\n",
    "                    continue\n",
    "\n",
    "                anchor_w, anchor_h = anchors[a]\n",
    "\n",
    "                # 解码 bbox\n",
    "                cx = (sigmoid(tx) + x) * stride\n",
    "                cy = (sigmoid(ty) + y) * stride\n",
    "                bw = np.exp(tw) * anchor_w\n",
    "                bh = np.exp(th) * anchor_h\n",
    "\n",
    "                x1 = cx - bw / 2\n",
    "                y1 = cy - bh / 2\n",
    "                x2 = cx + bw / 2\n",
    "                y2 = cy + bh / 2\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2, conf])\n",
    "    return boxes\n",
    "\n",
    "def compute_iou_batch(box1, boxes):\n",
    "    x1 = np.maximum(box1[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box1[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box1[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box1[3], boxes[:, 3])\n",
    "    inter = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union = area1 + area2 - inter\n",
    "    return inter / (union + 1e-6)\n",
    "\n",
    "def nms_numpy(boxes, iou_thres=0.45):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes[np.argsort(-boxes[:, 4])]\n",
    "    keep = []\n",
    "    while len(boxes) > 0:\n",
    "        best = boxes[0]\n",
    "        keep.append(best.tolist())\n",
    "        boxes = boxes[1:]\n",
    "        if len(boxes) == 0:\n",
    "            break\n",
    "        ious = compute_iou_batch(best, boxes)\n",
    "        boxes = boxes[ious < iou_thres]\n",
    "    return keep\n",
    "\n",
    "def postprocess_yolov5_all_layers(outputs, anchors_list, strides, conf_thres=0.25, iou_thres=0.45):\n",
    "    \"\"\"\n",
    "    outputs: list of 3 ndarray, shapes: [(1, 80,80,18), (1, 40,40,18), (1, 20,20,18)]\n",
    "    anchors_list: list of 3 anchor sets, each (3, 2)\n",
    "    strides: [8, 16, 32]\n",
    "    \"\"\"\n",
    "    all_boxes = []\n",
    "    for output, anchors, stride in zip(outputs, anchors_list, strides):\n",
    "        boxes = decode_layer(output, anchors, stride, conf_thres)\n",
    "        all_boxes.extend(boxes)\n",
    "    final_boxes = nms_numpy(all_boxes, iou_thres)\n",
    "    return final_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "794a4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出来自你的模型\n",
    "output_s = outputs[0]  # shape (1, 80, 80, 18)\n",
    "output_m = outputs[1]  # shape (1, 40, 40, 18)\n",
    "output_l = outputs[2]  # shape (1, 20, 20, 18)\n",
    "\n",
    "# 3个尺度对应的 anchor (标准 yolov5s 的 anchor)\n",
    "anchors_s = np.array([[10, 13], [16, 30], [33, 23]])  # for 80x80\n",
    "anchors_m = np.array([[30, 61], [62, 45], [59, 119]]) # for 40x40\n",
    "anchors_l = np.array([[116, 90], [156, 198], [373, 326]])  # for 20x20\n",
    "\n",
    "results = postprocess_yolov5_all_layers(\n",
    "    [output_s, output_m, output_l],\n",
    "    [anchors_s, anchors_m, anchors_l],\n",
    "    strides=[8, 16, 32],\n",
    "    conf_thres=0.3,#0.3\n",
    "    iou_thres=0.3#0.45\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1880eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[221.7338228431314,\n",
       "  259.9608217104537,\n",
       "  310.4777765479654,\n",
       "  431.47788771234576,\n",
       "  0.9246807816707996],\n",
       " [317.1543213418752,\n",
       "  282.9812522823222,\n",
       "  479.83321490800677,\n",
       "  393.142787664593,\n",
       "  0.8965991803290199],\n",
       " [321.5585585572584,\n",
       "  411.0931885749319,\n",
       "  458.9922162034376,\n",
       "  536.0381813556173,\n",
       "  0.890225068261756],\n",
       " [305.4604513259721,\n",
       "  427.23475570658405,\n",
       "  365.1605412574601,\n",
       "  563.6910664556381,\n",
       "  0.8769455971650576],\n",
       " [256.84110372161916,\n",
       "  -1.9728813384613204,\n",
       "  461.26426904296926,\n",
       "  374.38755367054137,\n",
       "  0.850607086983435],\n",
       " [312.91411657584274,\n",
       "  74.62829296752798,\n",
       "  412.2242428804692,\n",
       "  288.88398592635974,\n",
       "  0.8362116172572139],\n",
       " [209.34346390515566,\n",
       "  534.426057824048,\n",
       "  312.7590022161603,\n",
       "  645.7585716332521,\n",
       "  0.8261422044153682],\n",
       " [318.86616282400684,\n",
       "  538.0090004314715,\n",
       "  401.07684903082446,\n",
       "  575.9358775128657,\n",
       "  0.8186142637089094],\n",
       " [268.78802150734066,\n",
       "  71.63611991183387,\n",
       "  356.0576936627209,\n",
       "  286.10467297808754,\n",
       "  0.7670178029682475],\n",
       " [332.5340341239247,\n",
       "  556.0160467573298,\n",
       "  395.9887779860768,\n",
       "  598.6147857257022,\n",
       "  0.5379443189874074],\n",
       " [310.55502291179926,\n",
       "  -725.209454669103,\n",
       "  407.94020719982416,\n",
       "  1097.6443394287974,\n",
       "  0.5211269358352832],\n",
       " [271.4174634075288,\n",
       "  -453.3186608404361,\n",
       "  360.95382295609755,\n",
       "  817.6038092523373,\n",
       "  0.39705631223930743]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a9e2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(frame, results, color=(0,255,0)):\n",
    "    for box in results:\n",
    "        x1, y1, x2, y2, conf = map(int, box[:5])\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, f\"{conf/255:.2f}\", (x1, y1-5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b0b162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_frame=draw_bboxes(frame.copy(), results, color=(0,255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cf7e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"/home/sunrise/Project20250627/render.jpg\",rendered_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa86ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
